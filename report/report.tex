\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[romanian]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{subcaption}

\geometry{margin=2.5cm}

% Code listing style
\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    numbers=left,
    numberstyle=\tiny\color{gray},
    breaklines=true,
    frame=single
}

\title{Practical Assignment - Machine Learning 2025 Fall\\
\large Restaurant Sales Analysis: Sauce Prediction and Product Ranking}
\author{Elisa Mercas \& Denis Munteanu}
\date{January 2025}

\begin{document}

\maketitle

\begin{abstract}
Acest raport prezintă implementarea și analiza unor algoritmi de Machine Learning aplicați pe un set de date cu tranzacții dintr-un restaurant. Scopul principal este de a prezice dacă un client va cumpăra un sos și de a crea un sistem de ranking pentru produse cu potențial de upselling. Am implementat Logistic Regression from scratch folosind Gradient Descent, precum și Naive Bayes și k-NN pentru ranking. Rezultatele arată că modelul LR \#1 obține un F1-score de 0.76 pentru predicția Crazy Sauce, iar pentru ranking, baseline-ul de popularitate obține cele mai bune rezultate cu Hit@5 de 0.66.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introducere}
%==============================================================================

\subsection{Descrierea Problemei}
Acest proiect abordează analiza datelor de vânzări dintr-un restaurant pentru a:
\begin{enumerate}
    \item \textbf{LR \#1}: Prezice dacă un client care comandă Crazy Schnitzel va cumpăra și Crazy Sauce
    \item \textbf{LR \#2}: Crea un sistem de recomandare pentru sosuri multiple
    \item \textbf{Ranking}: Construi un sistem de ranking pentru produse cu potențial de upselling
\end{enumerate}

\subsection{Descrierea Dataset-ului}
Dataset-ul conține tranzacții de la un restaurant, cu următoarele caracteristici:

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Statistică} & \textbf{Valoare} \\
\midrule
Perioada & 5 Septembrie - 3 Decembrie 2025 \\
Total bonuri & 7,869 \\
Total linii & 28,039 \\
Produse unice & 59 \\
Coș mediu & 3.56 produse per bon \\
Valoare medie coș & 67.87 RON \\
\bottomrule
\end{tabular}
\caption{Statistici dataset}
\label{tab:dataset-stats}
\end{table}

\subsubsection{Distribuția pe Categorii}
\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Categorie} & \textbf{Vânzări} \\
\midrule
Schnitzel & 6,978 \\
Sauce & 6,117 \\
Drinks & 5,962 \\
Mac \& Cheese & 3,546 \\
Sides & 2,918 \\
Other & 2,312 \\
Salad & 206 \\
\bottomrule
\end{tabular}
\caption{Distribuția vânzărilor pe categorii}
\label{tab:category-dist}
\end{table}

\subsubsection{Coloane Utilizate}
\begin{itemize}
    \item \texttt{id\_bon} -- Identificator unic pentru fiecare bon/tranzacție
    \item \texttt{data\_bon} -- Data și ora tranzacției
    \item \texttt{retail\_product\_name} -- Numele produsului
    \item \texttt{SalePriceWithVAT} -- Prețul cu TVA
\end{itemize}

\subsubsection{Sosuri Standalone}
Sosurile analizate sunt prezentate în tabelul \ref{tab:sauce-sales}.

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Sos} & \textbf{Vânzări} & \textbf{Procent} \\
\midrule
Crazy Sauce & 1,662 & 20.3\% \\
Cheddar Sauce & 1,100 & 13.1\% \\
Garlic Sauce & 778 & 9.4\% \\
Blueberry Sauce & 743 & 9.0\% \\
Spicy Sauce & 386 & 4.9\% \\
Tomato Sauce & 212 & 2.7\% \\
Pink Sauce & 147 & 1.9\% \\
Extra Cheddar Sauce & 24 & 0.3\% \\
\bottomrule
\end{tabular}
\caption{Vânzări sosuri (Total: 5,052 = 18\% din toate vânzările)}
\label{tab:sauce-sales}
\end{table}

%==============================================================================
\section{Preprocesarea Datelor}
%==============================================================================

\subsection{Feature Engineering}
Pentru a transforma datele brute în features utilizabile de algoritmi, am aplicat:

\subsubsection{Vectorul de Produse}
Pentru fiecare produs $p$ dintr-un bon, am creat:
\begin{itemize}
    \item \texttt{has\_p} -- variabilă binară (1 dacă produsul este în coș, 0 altfel)
    \item \texttt{count\_p} -- numărul de apariții ale produsului în coș
\end{itemize}

\subsubsection{Agregări la Nivel de Coș}
\begin{itemize}
    \item \texttt{cart\_size} -- numărul total de produse din coș
    \item \texttt{distinct\_products} -- numărul de produse unice
    \item \texttt{total\_value} -- $\sum$ SalePriceWithVAT
\end{itemize}

\subsubsection{Features Temporale}
\begin{itemize}
    \item \texttt{day\_of\_week} -- ziua săptămânii (1-7)
    \item \texttt{hour} -- ora tranzacției
    \item \texttt{is\_weekend} -- 1 dacă weekend, 0 altfel
\end{itemize}

\subsection{Împărțirea Datelor}
Am împărțit datele la nivel de \textbf{bon} (nu pe rânduri individuale) pentru a evita data leakage:
\begin{itemize}
    \item Training set: 80\% din bonuri
    \item Test set: 20\% din bonuri
    \item Stratified split pentru a menține proporțiile claselor
\end{itemize}

%==============================================================================
\section{Logistic Regression \#1: Crazy Sauce Prediction}
%==============================================================================

\subsection{Formularea Problemei}
\textbf{Obiectiv}: Pentru bonurile care conțin Crazy Schnitzel, prezice dacă bonul conține și Crazy Sauce.

\begin{itemize}
    \item \textbf{Input (X)}: 56 features ce descriu conținutul coșului (excluzând toate sosurile)
    \item \textbf{Output (y)}: 1 dacă Crazy Sauce este în coș, 0 altfel
    \item \textbf{Dataset}: 1,783 bonuri cu Crazy Schnitzel
    \item \textbf{Rată conversie}: 53.2\% (948 din 1,783 bonuri conțin și Crazy Sauce)
\end{itemize}

\subsection{Implementare Logistic Regression from Scratch}

\subsubsection{Funcția Sigmoid}
\begin{equation}
\sigma(z) = \frac{1}{1 + e^{-z}}
\end{equation}

\subsubsection{Cross-Entropy Loss}
\begin{equation}
\mathcal{L}(\theta) = -\frac{1}{m}\sum_{i=1}^{m}\left[y^{(i)}\log(\hat{y}^{(i)}) + (1-y^{(i)})\log(1-\hat{y}^{(i)})\right]
\end{equation}

\subsubsection{Gradient Descent Update}
\begin{equation}
\theta := \theta - \alpha \cdot \frac{1}{m}X^T(\sigma(X\theta) - y)
\end{equation}

unde $\alpha = 0.1$ este learning rate-ul.

\subsubsection{Regularizare L2}
Am adăugat regularizare L2 ($\lambda = 0.01$) pentru a preveni overfitting-ul:
\begin{equation}
\mathcal{L}_{reg}(\theta) = \mathcal{L}(\theta) + \frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2
\end{equation}

\subsubsection{Antrenare}
Modelul a fost antrenat pe 1,000 de iterații, cu loss-ul scăzând de la 0.6931 (inițial) la 0.5575 (final).

\subsection{Rezultate}

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Metrică} & \textbf{Valoare} \\
\midrule
Accuracy & 0.6975 \\
Precision & 0.6565 \\
Recall & 0.9053 \\
F1 Score & 0.7611 \\
Specificity & 0.4611 \\
\bottomrule
\end{tabular}
\caption{Rezultate LR \#1 pe setul de test (357 samples)}
\label{tab:lr1-results}
\end{table}

\subsubsection{Matricea de Confuzie}
\begin{table}[H]
\centering
\begin{tabular}{l|cc}
& \textbf{Predicted Neg} & \textbf{Predicted Pos} \\
\midrule
\textbf{Actual Neg} & 77 & 90 \\
\textbf{Actual Pos} & 18 & 172 \\
\end{tabular}
\caption{Matricea de confuzie LR \#1}
\label{tab:lr1-confusion}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{results/lr1_confusion_matrix.png}
\caption{Matricea de confuzie pentru LR \#1}
\label{fig:lr1-confusion}
\end{figure}

\subsubsection{ROC Curve și AUC}
Pentru a evalua capacitatea modelului de a discrimina între clase, am calculat curba ROC și scorul AUC.

\begin{table}[H]
\centering
\begin{tabular}{lc}
\toprule
\textbf{Metrică} & \textbf{Valoare} \\
\midrule
ROC-AUC & 0.7142 \\
\bottomrule
\end{tabular}
\caption{ROC-AUC pentru LR \#1}
\label{tab:lr1-auc}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{results/lr1_roc_curve.png}
\caption{Curba ROC pentru LR \#1. AUC de 0.71 indică o capacitate bună de discriminare, semnificativ peste baseline-ul aleator (AUC=0.5).}
\label{fig:lr1-roc}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.7\textwidth]{results/lr1_training_loss.png}
\caption{Evoluția loss-ului în timpul antrenării}
\label{fig:lr1-loss}
\end{figure}

\subsection{Interpretarea Coeficienților}
Coeficienții cu valori pozitive mari indică produse care cresc probabilitatea de a cumpăra Crazy Sauce, în timp ce coeficienții negativi indică produse care scad această probabilitate.

\begin{table}[H]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Feature} & \textbf{Coeficient} & \textbf{Efect} \\
\midrule
distinct\_products & +0.7846 & POZITIV \\
has\_Mac \& cheease & +0.3411 & POZITIV \\
has\_Pepsi Cola 0.25L Doze & +0.2795 & POZITIV \\
cart\_size & +0.2237 & POZITIV \\
has\_Aqua Carpatica Minerala & +0.1547 & POZITIV \\
\midrule
has\_Breaded Chicken Schnitzel & -0.4179 & NEGATIV \\
has\_Crazy Fries with Parmesan & -0.3659 & NEGATIV \\
has\_Prigat Still Orange & -0.3309 & NEGATIV \\
has\_Breaded Pork Schnitzel & -0.2659 & NEGATIV \\
has\_Mac \& Cheese with Bacon & -0.2593 & NEGATIV \\
\bottomrule
\end{tabular}
\caption{Top features pentru predicția Crazy Sauce}
\label{tab:lr1-features}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{results/lr1_feature_importance.png}
\caption{Importanța features pentru LR \#1}
\label{fig:lr1-features}
\end{figure}

\textbf{Interpretare}: Clienții cu coșuri mai diverse (distinct\_products mare) și care comandă Mac \& Cheese au o probabilitate mai mare să cumpere Crazy Sauce. Pe de altă parte, cei care comandă alt tip de schnitzel (Breaded Chicken sau Pork) nu mai cumpără Crazy Sauce.

\subsection{Comparație cu Baseline}
Baseline-ul (majority class) ar prezice întotdeauna clasa majoritară (pozitivă = 53.2\%), obținând o accuracy de 53.2\%. Modelul nostru cu accuracy de 69.75\% depășește semnificativ baseline-ul.

%==============================================================================
\section{Logistic Regression \#2: Multi-Sauce Recommendation}
%==============================================================================

\subsection{Formularea Problemei}
Pentru fiecare sos $s$ din lista de sosuri, am antrenat un model separat:
\begin{itemize}
    \item \textbf{Input (X)}: Features ale coșului (excluzând toate sosurile)
    \item \textbf{Output ($y_s$)}: 1 dacă sosul $s$ este în coș, 0 altfel
\end{itemize}

\subsection{Pseudo-Recomandare}
Pentru un coș dat (fără sos), calculăm $P(s | \text{coș})$ pentru fiecare sos și recomandăm Top-K sosuri cu probabilitatea cea mai mare.

\textbf{Exemplu de recomandare} pentru un coș cu Crazy Schnitzel, French Fries, la ora 13:00:
\begin{itemize}
    \item Crazy Sauce: 21.7\% probabilitate
    \item Cheddar Sauce: 3.9\% probabilitate
    \item Garlic Sauce: 3.9\% probabilitate
\end{itemize}

\subsection{Evaluare Hit@K pentru Recomandare}
Am evaluat sistemul de recomandare folosind metrica Hit@K: pentru fiecare bon de test care conține un sos, verificăm dacă sosul real apare în Top-K recomandări.

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Metodă} & \textbf{Hit@1} & \textbf{Hit@3} & \textbf{Hit@5} \\
\midrule
LR Recommendation & 0.4320 & 0.7720 & 0.9400 \\
Popularity Baseline & 0.3780 & 0.7440 & 0.9320 \\
\bottomrule
\end{tabular}
\caption{Comparație Hit@K: LR Recommendation vs Popularity Baseline}
\label{tab:lr2-hitk}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/lr2_hitk_comparison.png}
\caption{Comparație Hit@K între sistemul LR și baseline-ul de popularitate}
\label{fig:lr2-hitk}
\end{figure}

\textbf{Observație}: Sistemul LR depășește baseline-ul de popularitate la toate metricile, în special la Hit@1 (43.2\% vs 37.8\%), demonstrând că folosirea features contextuale (conținutul coșului, tipul de schnitzel) aduce valoare adăugată față de recomandarea simplă bazată pe popularitate globală. La Hit@5, ambele sisteme ating performanțe foarte bune (>93\%).

\subsection{Rezultate Comparative}

\begin{table}[H]
\centering
\begin{tabular}{lccccc}
\toprule
\textbf{Sos} & \textbf{Base Rate} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
\midrule
Crazy Sauce & 20.3\% & 0.8424 & 0.6291 & 0.5423 & 0.5825 \\
Cheddar Sauce & 13.1\% & 0.8698 & 0.5094 & 0.1311 & 0.2085 \\
Blueberry Sauce & 9.0\% & 0.9111 & 0.5294 & 0.1268 & 0.2045 \\
Garlic Sauce & 9.4\% & 0.9041 & 0.4091 & 0.0612 & 0.1065 \\
Spicy Sauce & 4.9\% & 0.9524 & 0.6667 & 0.0263 & 0.0506 \\
Extra Cheddar Sauce & 0.3\% & 0.9968 & 0.0000 & 0.0000 & 0.0000 \\
Tomato Sauce & 2.7\% & 0.9733 & 0.0000 & 0.0000 & 0.0000 \\
Pink Sauce & 1.9\% & 0.9816 & 0.0000 & 0.0000 & 0.0000 \\
\bottomrule
\end{tabular}
\caption{Performanța modelelor per sos}
\label{tab:lr2-results}
\end{table}

\textbf{Observație}: Sosurile rare (Extra Cheddar, Tomato, Pink) au F1=0 deoarece modelul nu poate învăța suficiente pattern-uri din puținele exemple pozitive.

\subsection{Top Features pentru Fiecare Sos}

\begin{table}[H]
\centering
\small
\begin{tabular}{ll}
\toprule
\textbf{Sos} & \textbf{Top 3 Features (pozitive)} \\
\midrule
Crazy Sauce & distinct\_products (+0.59), has\_Crazy Schnitzel (+0.56), has\_Mac (+0.31) \\
Cheddar Sauce & distinct\_products (+0.45), cart\_size (+0.30), has\_Breaded Chicken (+0.28) \\
Blueberry Sauce & distinct\_products (+0.43), has\_Viennese Schnitzel (+0.39), cart\_size (+0.18) \\
Garlic Sauce & distinct\_products (+0.50), cart\_size (+0.37), has\_Breaded Chicken (+0.21) \\
Spicy Sauce & distinct\_products (+0.30), has\_Viennese Schnitzel (+0.29), has\_Pepsi (+0.13) \\
\bottomrule
\end{tabular}
\caption{Top features per sos}
\label{tab:lr2-features}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{results/lr2_performance_heatmap.png}
\caption{Heatmap performanță multi-sauce}
\label{fig:lr2-heatmap}
\end{figure}

%==============================================================================
\section{Ranking pentru Upselling}
%==============================================================================

\subsection{Formularea Problemei}
Scopul este de a construi o metodă care produce o ierarhie de produse candidate pentru upselling.

\subsubsection{Produse Candidate}
Am selectat 30 de produse pentru ranking: 8 sosuri, 11 băuturi și 11 garnituri.

\subsubsection{Scor de Ranking}
\begin{equation}
\text{Score}(p | \text{coș}) = P(p | \text{coș}) \times \text{price}(p)
\end{equation}

Acest scor maximizează valoarea așteptată a vânzărilor (Expected Value).

\subsection{Top Produse după Expected Value}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Produs} & \textbf{Preț} & \textbf{P(cumparare)} & \textbf{Expected Value} \\
\midrule
Mac \& cheease & 32.9 & 28.4\% & 9.34 RON \\
Breaded Chicken Schnitzel & 27.9 & 24.7\% & 6.90 RON \\
Crazy Schnitzel & 28.9 & 22.7\% & 6.55 RON \\
Viennese Schnitzel & 48.9 & 8.6\% & 4.19 RON \\
Mac \& Cheese with Bacon & 25.9 & 14.6\% & 3.77 RON \\
\bottomrule
\end{tabular}
\caption{Top 5 produse după Expected Value general}
\label{tab:ranking-ev}
\end{table}

\subsection{Upsell pentru Crazy Schnitzel}
Pentru clienții care comandă Crazy Schnitzel, cele mai bune recomandări sunt:

\begin{table}[H]
\centering
\begin{tabular}{lccc}
\toprule
\textbf{Produs} & \textbf{P(condițională)} & \textbf{Expected Value} \\
\midrule
Mac \& cheease & 49.4\% & 16.24 RON \\
Baked potatoes & 36.8\% & 4.75 RON \\
Pepsi Cola 0.25L & 36.2\% & 4.35 RON \\
Crazy Sauce & 53.2\% & 3.67 RON \\
Aqua Carpatica 0.5L & 25.9\% & 2.46 RON \\
\bottomrule
\end{tabular}
\caption{Top upsell pentru Crazy Schnitzel}
\label{tab:ranking-crazy}
\end{table}

\subsection{Algoritmi Implementați}

\subsubsection{Naive Bayes (from scratch)}
Am implementat Gaussian Naive Bayes pentru estimarea $P(p | \text{coș})$:
\begin{equation}
P(C_k | x) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i | C_k)}{P(x)}
\end{equation}

unde presupunem că features sunt distribuite Gaussian:
\begin{equation}
P(x_i | C_k) = \frac{1}{\sqrt{2\pi\sigma_{ki}^2}}\exp\left(-\frac{(x_i - \mu_{ki})^2}{2\sigma_{ki}^2}\right)
\end{equation}

\subsubsection{k-Nearest Neighbors (from scratch)}
Am implementat k-NN cu voting ponderat după distanță:
\begin{equation}
P(C | x) = \frac{\sum_{i \in N_k(x)} w_i \cdot \mathbb{1}[y_i = C]}{\sum_{i \in N_k(x)} w_i}
\end{equation}

unde $w_i = \frac{1}{d(x, x_i)}$ pentru voting ponderat.

\subsection{Experimental Setup}
Pentru evaluare, pentru fiecare bon din test:
\begin{enumerate}
    \item Construim un "coș parțial" eliminând 1 produs din cele 30 candidate
    \item Folosim algoritmul de ranking pentru a genera Top-K recomandări
    \item Verificăm dacă produsul eliminat apare în Top-K
\end{enumerate}

\textbf{Dataset}: Training set: 6,295 bonuri; Test set: 1,574 bonuri (200 evaluate).

\subsection{Rezultate}

\begin{table}[H]
\centering
\begin{tabular}{lcccc}
\toprule
\textbf{Algoritm} & \textbf{Hit@1} & \textbf{Hit@3} & \textbf{Hit@5} & \textbf{MRR} \\
\midrule
Naive Bayes (scratch) & 0.0060 & 0.0302 & 0.0967 & 0.0307 \\
k-NN (scratch) & 0.0000 & 0.4125 & 0.5750 & 0.2104 \\
\textbf{Popularity Baseline} & \textbf{0.2205} & \textbf{0.4441} & \textbf{0.6586} & \textbf{0.3635} \\
Revenue Baseline & 0.2024 & 0.3263 & 0.6163 & 0.3177 \\
\bottomrule
\end{tabular}
\caption{Performanța algoritmilor de ranking}
\label{tab:ranking-results}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/ranking_comparison.png}
\caption{Comparație algoritmi de ranking}
\label{fig:ranking-comparison}
\end{figure}

\subsection{Exemple de Recomandări}

\begin{table}[H]
\centering
\small
\begin{tabular}{p{5cm}p{7cm}c}
\toprule
\textbf{Produse în coș} & \textbf{Top 3 Naive Bayes} & \textbf{Hit?} \\
\midrule
Breaded Chicken Schnitzel, Crazy Schnitzel, Extra parmezan, Aqua, Blueberry Sauce & Crazy Fries Cheddar bacon (25.9), Crazy Fries Parmesan (24.9), Baked potatoes (12.9) & $\checkmark$ \\
\midrule
Viennese Schnitzel, Crazy Fries Parmesan, Extra bacon, Pepsi Zero, Blueberry Sauce & Crazy Fries Cheddar bacon (25.9), Crazy Fries Parmesan (24.9), Baked potatoes (12.9) & $\checkmark$ \\
\bottomrule
\end{tabular}
\caption{Exemple de recomandări cu Naive Bayes}
\label{tab:ranking-examples}
\end{table}

\subsection{Discuție Rezultate}
\textbf{De ce Popularity Baseline bate algoritmii from scratch?}
\begin{itemize}
    \item \textbf{Curse of dimensionality}: Cu 35 features și ~6,000 exemple, algoritmii estimează prost probabilitățile
    \item \textbf{Class imbalance}: Produsele rare au puține exemple pozitive
    \item \textbf{Simplicitate}: Popularitatea globală e un semnal puternic în retail
\end{itemize}

%==============================================================================
\section{Concluzii}
%==============================================================================

\subsection{Rezultate Principale}
\begin{itemize}
    \item \textbf{LR \#1}: Modelul de Logistic Regression from scratch atinge un F1-score de 0.76 pentru predicția Crazy Sauce, depășind baseline-ul de majority class cu 16.5 puncte procentuale (accuracy 69.75\% vs 53.2\%).
    
    \item \textbf{LR \#2}: Sistemul de recomandare multi-sos funcționează bine pentru sosurile populare (Crazy Sauce F1=0.58), dar are dificultăți cu sosurile rare (Extra Cheddar, Tomato, Pink cu F1=0).
    
    \item \textbf{Ranking}: Popularity Baseline obține cele mai bune rezultate (Hit@5=0.66, MRR=0.36), depășind algoritmii from scratch. Acest rezultat e consistent cu literatura de specialitate în sisteme de recomandare.
\end{itemize}

\subsection{Variante Încercate și Lecții Învățate}
\textbf{Ce nu a funcționat bine:}
\begin{itemize}
    \item \textbf{Learning rate prea mare (>0.5)}: convergență instabilă, oscilații în loss
    \item \textbf{Fără regularizare L2}: overfitting pe setul de antrenare
    \item \textbf{Features de interacțiune}: am încercat produse carteziene (ex. Schnitzel × Drink), dar au crescut dimensionalitatea fără beneficiu semnificativ
    \item \textbf{One-hot encoding pentru ore}: mai puțin eficient decât ora ca feature numeric
\end{itemize}

\textbf{Ce am învățat:}
\begin{enumerate}
    \item Feature-ul \texttt{distinct\_products} este cel mai predictiv pentru toate sosurile
    \item Există corelații puternice între tipul de schnitzel și sosul ales
    \item Baseline-urile simple sunt competitivi în setări cu date limitate
    \item Normalizarea features (z-score) este esențială pentru convergența gradient descent
\end{enumerate}

\subsection{Direcții de Îmbunătățire}
\begin{enumerate}
    \item \textbf{Features suplimentare}: sezonalitate, time-series, cross-sell patterns
    \item \textbf{Ensemble methods}: combinarea Naive Bayes + k-NN + Popularity
    \item \textbf{Matrix Factorization}: pentru capturarea pattern-urilor latente
    \item \textbf{Deep Learning}: rețele neurale pentru embedding produse
    \item \textbf{Cross-validation}: pentru optimizarea hiperparametrilor
\end{enumerate}

%==============================================================================
\section{Contribuții}
%==============================================================================

\begin{itemize}
    \item \textbf{Elisa Mercas}: Implementare Logistic Regression from scratch, preprocesare date, EDA, notebook-uri 01-03
    \item \textbf{Denis Munteanu}: Implementare Ranking (Naive Bayes, k-NN from scratch), evaluare Hit@K, notebook-uri 04-05, raport LaTeX
\end{itemize}

%==============================================================================
\section{Anexe}
%==============================================================================

\subsection{Instrucțiuni de Rulare}

\begin{lstlisting}[language=bash]
# Install dependencies
pip install -r requirements.txt

# Run notebooks in order
jupyter notebook notebooks/

# Notebooks order: 01_eda -> 02_lr_crazy_sauce -> 
#                  03_lr_multi_sauce -> 04_ranking_upsell -> 05_ranking_ml
\end{lstlisting}

\subsection{Structura Repository}
\begin{verbatim}
├── data/raw/           # Dataset (ap_dataset.csv)
├── data/processed/     # Preprocessed features
├── src/                # Source code
│   ├── data_loader.py
│   ├── preprocessing.py
│   └── models/
│       ├── logistic_regression.py  # LR from scratch
│       ├── evaluation.py           # Metrics
│       └── ranking.py              # NB + k-NN from scratch
├── notebooks/          # Jupyter notebooks (5 files)
├── results/            # Generated figures (24 PNG files)
└── report/             # LaTeX report
\end{verbatim}

\subsection{Figuri Suplimentare}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/top_products.png}
\caption{Top produse după vânzări}
\label{fig:top-products}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/sauce_popularity.png}
\caption{Popularitatea sosurilor}
\label{fig:sauce-popularity}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{results/daily_sales.png}
\caption{Vânzări pe zile}
\label{fig:daily-sales}
\end{figure}

\end{document}
