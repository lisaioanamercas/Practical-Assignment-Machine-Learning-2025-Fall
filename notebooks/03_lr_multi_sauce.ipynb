{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Logistic Regression #2: Multi-Sauce Recommendation System\n",
                "\n",
                "## Objective\n",
                "Build a recommendation system that predicts which sauce(s) a customer is likely to purchase based on their cart contents.\n",
                "\n",
                "We train **one model per sauce** and compare their performance.\n",
                "\n",
                "### Available Sauces:\n",
                "- Crazy Sauce\n",
                "- Cheddar Sauce\n",
                "- Extra Cheddar Sauce\n",
                "- Garlic Sauce\n",
                "- Tomato Sauce\n",
                "- Blueberry Sauce\n",
                "- Spicy Sauce\n",
                "- Pink Sauce"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Imports\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from pathlib import Path\n",
                "import sys\n",
                "\n",
                "# Add src to path\n",
                "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
                "\n",
                "from data_loader import load_raw_data, SAUCES\n",
                "from preprocessing import prepare_lr_data, normalize_features, get_feature_names\n",
                "from models.logistic_regression import LogisticRegression\n",
                "from models.evaluation import (\n",
                "    accuracy, precision, recall, f1_score, \n",
                "    confusion_matrix, classification_report\n",
                ")\n",
                "\n",
                "# Settings\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"Available sauces:\")\n",
                "for sauce in SAUCES:\n",
                "    print(f\"  - {sauce}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load raw data\n",
                "DATA_PATH = Path('../data/raw/ap_dataset.csv')\n",
                "df = load_raw_data(DATA_PATH)\n",
                "\n",
                "print(f\"Dataset: {len(df)} rows, {df['id_bon'].nunique()} receipts\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check sauce distribution\n",
                "sauce_counts = {}\n",
                "total_receipts = df['id_bon'].nunique()\n",
                "\n",
                "for sauce in SAUCES:\n",
                "    count = df[df['retail_product_name'] == sauce]['id_bon'].nunique()\n",
                "    sauce_counts[sauce] = {\n",
                "        'count': count,\n",
                "        'percentage': 100 * count / total_receipts\n",
                "    }\n",
                "\n",
                "sauce_df = pd.DataFrame(sauce_counts).T\n",
                "sauce_df = sauce_df.sort_values('count', ascending=False)\n",
                "print(\"Sauce Purchase Rates:\")\n",
                "sauce_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train Models for Each Sauce"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Store results\n",
                "models = {}\n",
                "results = {}\n",
                "\n",
                "for sauce in SAUCES:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Training model for: {sauce}\")\n",
                "    print('='*60)\n",
                "    \n",
                "    # Prepare data (no filter - all receipts)\n",
                "    try:\n",
                "        X, y, features_df = prepare_lr_data(\n",
                "            df,\n",
                "            target_sauce=sauce,\n",
                "            filter_product=None,  # All receipts\n",
                "            exclude_all_sauces=True\n",
                "        )\n",
                "    except Exception as e:\n",
                "        print(f\"  Error preparing data: {e}\")\n",
                "        continue\n",
                "    \n",
                "    # Check if we have enough positive samples\n",
                "    if y.sum() < 10:\n",
                "        print(f\"  Skipping - not enough positive samples ({y.sum()})\")\n",
                "        continue\n",
                "    \n",
                "    print(f\"  Samples: {len(y)}, Positive: {y.sum()} ({100*y.mean():.1f}%)\")\n",
                "    \n",
                "    # Train/test split\n",
                "    X_train, X_test, y_train, y_test = train_test_split(\n",
                "        X, y, test_size=0.2, random_state=42, stratify=y\n",
                "    )\n",
                "    \n",
                "    # Normalize\n",
                "    X_train_norm, mean, std = normalize_features(X_train)\n",
                "    X_test_norm, _, _ = normalize_features(X_test, mean=mean, std=std)\n",
                "    \n",
                "    # Train model\n",
                "    model = LogisticRegression(\n",
                "        learning_rate=0.1,\n",
                "        n_iterations=500,\n",
                "        regularization=0.01,\n",
                "        verbose=False\n",
                "    )\n",
                "    model.fit(X_train_norm, y_train)\n",
                "    \n",
                "    # Evaluate\n",
                "    y_pred = model.predict(X_test_norm)\n",
                "    \n",
                "    report = classification_report(y_test, y_pred)\n",
                "    \n",
                "    print(f\"  Accuracy:  {report['accuracy']:.4f}\")\n",
                "    print(f\"  Precision: {report['precision']:.4f}\")\n",
                "    print(f\"  Recall:    {report['recall']:.4f}\")\n",
                "    print(f\"  F1 Score:  {report['f1_score']:.4f}\")\n",
                "    \n",
                "    # Store\n",
                "    models[sauce] = {\n",
                "        'model': model,\n",
                "        'mean': mean,\n",
                "        'std': std,\n",
                "        'feature_names': get_feature_names(features_df)\n",
                "    }\n",
                "    results[sauce] = {\n",
                "        'samples': len(y),\n",
                "        'positive_rate': y.mean(),\n",
                "        **report\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Compare Model Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create comparison DataFrame\n",
                "comparison_data = []\n",
                "for sauce, res in results.items():\n",
                "    comparison_data.append({\n",
                "        'Sauce': sauce,\n",
                "        'Base Rate': res['positive_rate'],\n",
                "        'Accuracy': res['accuracy'],\n",
                "        'Precision': res['precision'],\n",
                "        'Recall': res['recall'],\n",
                "        'F1 Score': res['f1_score'] \n",
                "    })\n",
                "\n",
                "comparison_df = pd.DataFrame(comparison_data)\n",
                "comparison_df = comparison_df.sort_values('F1 Score', ascending=False)\n",
                "\n",
                "print(\"Model Performance Comparison:\")\n",
                "comparison_df.round(4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualization - metrics comparison\n",
                "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
                "\n",
                "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
                "colors = ['steelblue', 'seagreen', 'coral', 'mediumpurple']\n",
                "\n",
                "for ax, metric, color in zip(axes.flatten(), metrics, colors):\n",
                "    data = comparison_df.sort_values(metric, ascending=True)\n",
                "    ax.barh(data['Sauce'], data[metric], color=color)\n",
                "    ax.set_xlabel(metric)\n",
                "    ax.set_title(f'{metric} by Sauce')\n",
                "    ax.set_xlim(0, 1)\n",
                "    \n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/lr2_metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Heatmap of all metrics\n",
                "fig, ax = plt.subplots(figsize=(10, 8))\n",
                "\n",
                "heatmap_data = comparison_df.set_index('Sauce')[['Base Rate', 'Accuracy', 'Precision', 'Recall', 'F1 Score']]\n",
                "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlGnBu', ax=ax,\n",
                "            cbar_kws={'label': 'Score'})\n",
                "ax.set_title('Multi-Sauce Model Performance Heatmap')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/lr2_performance_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Feature Importance Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top features for each sauce\n",
                "print(\"Top 5 Features for Each Sauce Model:\")\n",
                "print(\"=\" * 70)\n",
                "\n",
                "for sauce, model_data in models.items():\n",
                "    model = model_data['model']\n",
                "    feature_names = model_data['feature_names']\n",
                "    \n",
                "    importance = model.get_feature_importance(feature_names)\n",
                "    top_5 = list(importance.items())[:5]\n",
                "    \n",
                "    print(f\"\\n{sauce}:\")\n",
                "    for name, data in top_5:\n",
                "        direction = \"+\" if data['weight'] > 0 else \"-\"\n",
                "        print(f\"  {direction} {name}: {data['weight']:+.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature importance heatmap for top features\n",
                "# Get union of top 10 features across all models\n",
                "all_top_features = set()\n",
                "for sauce, model_data in models.items():\n",
                "    importance = model_data['model'].get_feature_importance(model_data['feature_names'])\n",
                "    all_top_features.update(list(importance.keys())[:10])\n",
                "\n",
                "all_top_features = list(all_top_features)\n",
                "\n",
                "# Create weight matrix\n",
                "weight_matrix = pd.DataFrame(index=all_top_features, columns=list(models.keys()))\n",
                "\n",
                "for sauce, model_data in models.items():\n",
                "    importance = model_data['model'].get_feature_importance(model_data['feature_names'])\n",
                "    for feat in all_top_features:\n",
                "        if feat in importance:\n",
                "            weight_matrix.loc[feat, sauce] = importance[feat]['weight']\n",
                "        else:\n",
                "            weight_matrix.loc[feat, sauce] = 0\n",
                "\n",
                "weight_matrix = weight_matrix.astype(float)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize feature weights across sauces\n",
                "fig, ax = plt.subplots(figsize=(14, 10))\n",
                "sns.heatmap(weight_matrix, annot=True, fmt='.2f', cmap='RdBu_r', center=0, ax=ax,\n",
                "            cbar_kws={'label': 'Weight'})\n",
                "ax.set_title('Feature Weights Across Sauce Models\\n(Red = positive, Blue = negative)')\n",
                "ax.set_xlabel('Sauce')\n",
                "ax.set_ylabel('Feature')\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.tight_layout()\n",
                "plt.savefig('../results/lr2_feature_weights_heatmap.png', dpi=150, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Recommendation Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def recommend_sauces(cart_features, models, top_n=3):\n",
                "    \"\"\"\n",
                "    Recommend top N sauces based on cart features.\n",
                "    \n",
                "    Args:\n",
                "        cart_features: Dictionary of feature_name -> value\n",
                "        models: Dictionary of sauce -> model info\n",
                "        top_n: Number of sauces to recommend\n",
                "        \n",
                "    Returns:\n",
                "        List of (sauce_name, probability) tuples\n",
                "    \"\"\"\n",
                "    predictions = []\n",
                "    \n",
                "    for sauce, model_data in models.items():\n",
                "        model = model_data['model']\n",
                "        mean = model_data['mean']\n",
                "        std = model_data['std']\n",
                "        feature_names = model_data['feature_names']\n",
                "        \n",
                "        # Create feature vector\n",
                "        X = np.zeros(len(feature_names))\n",
                "        for i, feat in enumerate(feature_names):\n",
                "            if feat in cart_features:\n",
                "                X[i] = cart_features[feat]\n",
                "        \n",
                "        # Normalize\n",
                "        X_norm = (X - mean) / std\n",
                "        \n",
                "        # Predict\n",
                "        prob = model.predict_proba(X_norm.reshape(1, -1))[0]\n",
                "        predictions.append((sauce, prob))\n",
                "    \n",
                "    # Sort by probability\n",
                "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
                "    \n",
                "    return predictions[:top_n]\n",
                "\n",
                "# Example usage\n",
                "example_cart = {\n",
                "    'has_Crazy Schnitzel': 1,\n",
                "    'has_French fries': 1,\n",
                "    'cart_size': 3,\n",
                "    'total_value': 50,\n",
                "    'hour': 13,\n",
                "    'is_weekend': 0\n",
                "}\n",
                "\n",
                "print(\"Example Recommendation:\")\n",
                "print(f\"Cart: {example_cart}\")\n",
                "print(\"\\nRecommended Sauces:\")\n",
                "recommendations = recommend_sauces(example_cart, models, top_n=3)\n",
                "for sauce, prob in recommendations:\n",
                "    print(f\"  {sauce}: {prob:.1%} probability\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"=\" * 70)\n",
                "print(\"MULTI-SAUCE RECOMMENDATION SYSTEM SUMMARY\")\n",
                "print(\"=\" * 70)\n",
                "print(f\"\\nModels trained: {len(models)}\")\n",
                "print(f\"\\nPerformance Summary:\")\n",
                "\n",
                "avg_acc = comparison_df['Accuracy'].mean()\n",
                "avg_f1 = comparison_df['F1 Score'].mean()\n",
                "best_sauce = comparison_df.iloc[0]['Sauce']\n",
                "best_f1 = comparison_df.iloc[0]['F1 Score']\n",
                "\n",
                "print(f\"  Average Accuracy: {avg_acc:.4f}\")\n",
                "print(f\"  Average F1 Score: {avg_f1:.4f}\")\n",
                "print(f\"  Best Model: {best_sauce} (F1: {best_f1:.4f})\")\n",
                "\n",
                "print(f\"\\nRecommendation System Ready!\")\n",
                "print(f\"Use recommend_sauces(cart_features, models) to get recommendations.\")\n",
                "print(\"=\" * 70)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}